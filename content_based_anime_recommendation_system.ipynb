{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAE1hDzbKqiT"
   },
   "source": [
    "# ANIME CONTENT BASED RECOMMENDATION SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "4_yCkh8We7CM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"anime_with_synopsis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TuSkiA9E0zSn",
    "outputId": "1a44edb2-c14f-47c1-8e84-a481cb2f4591"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>sypnopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.78</td>\n",
       "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>8.39</td>\n",
       "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
       "      <td>other day, another bounty—such is the life of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>8.24</td>\n",
       "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>7.27</td>\n",
       "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
       "      <td>ches are individuals with special powers like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>6.98</td>\n",
       "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID                             Name Score  \\\n",
       "0       1                     Cowboy Bebop  8.78   \n",
       "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
       "2       6                           Trigun  8.24   \n",
       "3       7               Witch Hunter Robin  7.27   \n",
       "4       8                   Bouken Ou Beet  6.98   \n",
       "\n",
       "                                              Genres  \\\n",
       "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
       "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
       "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
       "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
       "4          Adventure, Fantasy, Shounen, Supernatural   \n",
       "\n",
       "                                           sypnopsis  \n",
       "0  In the year 2071, humanity has colonized sever...  \n",
       "1  other day, another bounty—such is the life of ...  \n",
       "2  Vash the Stampede is the man with a $$60,000,0...  \n",
       "3  ches are individuals with special powers like ...  \n",
       "4  It is the dark century and the people are suff...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JN_pGP-IQuV",
    "outputId": "1c138349-7dd0-477b-dbec-f55c230dbbb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAL_ID       0\n",
       "Name         0\n",
       "Score        0\n",
       "Genres       0\n",
       "sypnopsis    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the number of missing values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qGi4QxAaIp0X"
   },
   "outputs": [],
   "source": [
    "#dropna will drop all missing values from your original dataset\n",
    "# dropna()-->>tüm NaN değerleri siler\n",
    "#Yapılan değişiklikleri kalıcı hale getirmek için inplace=True\n",
    "#parametresini verdik.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lb_arvovIu1W",
    "outputId": "d8748769-8be9-48dd-b839-ced5b01bc16a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method returns a Series with True and False values \n",
    "#that describe which rows in the DataFrame are \"duplicated\" and no\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "14t-dwinEn6v"
   },
   "outputs": [],
   "source": [
    "df[\"Score\"] = df[\"Score\"].map(lambda x:np.nan if x==\"Unknown\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "5KlbFuPgFpSf"
   },
   "outputs": [],
   "source": [
    "df[\"Score\"].fillna(df[\"Score\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "yiksqvfXGCcV"
   },
   "outputs": [],
   "source": [
    "df[\"Score\"] = df[\"Score\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFdmq-KHF2C8",
    "outputId": "35895855-a47a-4c04-a860-002755c2db93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16206 entries, 0 to 16213\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   MAL_ID     16206 non-null  int64  \n",
      " 1   Name       16206 non-null  object \n",
      " 2   Score      16206 non-null  float64\n",
      " 3   Genres     16206 non-null  object \n",
      " 4   sypnopsis  16206 non-null  object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 759.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "lhYXADrSCJKV",
    "outputId": "20cb566d-f3ed-4820-e213-d90b1a8f6111"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>sypnopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.19</td>\n",
       "      <td>Action, Military, Adventure, Comedy, Drama, Ma...</td>\n",
       "      <td>\"In order for something to be obtained, someth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14647</th>\n",
       "      <td>40028</td>\n",
       "      <td>Shingeki no Kyojin: The Final Season</td>\n",
       "      <td>9.17</td>\n",
       "      <td>Action, Military, Mystery, Super Power, Drama,...</td>\n",
       "      <td>Gabi Braun and Falco Grice have been training ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.11</td>\n",
       "      <td>Thriller, Sci-Fi</td>\n",
       "      <td>The self-proclaimed mad scientist Rintarou Oka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>11061</td>\n",
       "      <td>Hunter x Hunter (2011)</td>\n",
       "      <td>9.10</td>\n",
       "      <td>Action, Adventure, Fantasy, Shounen, Super Power</td>\n",
       "      <td>Hunter x Hunter is set in a world where Hunter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>9.10</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>Gintoki, Shinpachi, and Kagura return as the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>38524</td>\n",
       "      <td>Shingeki no Kyojin Season 3 Part 2</td>\n",
       "      <td>9.10</td>\n",
       "      <td>Action, Drama, Fantasy, Military, Mystery, Sho...</td>\n",
       "      <td>Seeking to restore humanity's diminishing hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5234</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama'</td>\n",
       "      <td>9.08</td>\n",
       "      <td>Action, Sci-Fi, Comedy, Historical, Parody, Sa...</td>\n",
       "      <td>fter a one-year hiatus, Shinpachi Shimura retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>820</td>\n",
       "      <td>Ginga Eiyuu Densetsu</td>\n",
       "      <td>9.07</td>\n",
       "      <td>Military, Sci-Fi, Space, Drama</td>\n",
       "      <td>The 150-year-long stalemate between the two in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>15417</td>\n",
       "      <td>Gintama': Enchousen</td>\n",
       "      <td>9.04</td>\n",
       "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
       "      <td>hile Gintoki Sakata was away, the Yorozuya fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8854</th>\n",
       "      <td>28851</td>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>9.00</td>\n",
       "      <td>Drama, School, Shounen</td>\n",
       "      <td>s a wild youth, elementary school student Shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAL_ID                                  Name  Score  \\\n",
       "3446     5114      Fullmetal Alchemist: Brotherhood   9.19   \n",
       "14647   40028  Shingeki no Kyojin: The Final Season   9.17   \n",
       "4953     9253                           Steins;Gate   9.11   \n",
       "5660    11061                Hunter x Hunter (2011)   9.10   \n",
       "8879    28977                              Gintama°   9.10   \n",
       "13720   38524    Shingeki no Kyojin Season 3 Part 2   9.10   \n",
       "5234     9969                              Gintama'   9.08   \n",
       "723       820                  Ginga Eiyuu Densetsu   9.07   \n",
       "6377    15417                   Gintama': Enchousen   9.04   \n",
       "8854    28851                        Koe no Katachi   9.00   \n",
       "\n",
       "                                                  Genres  \\\n",
       "3446   Action, Military, Adventure, Comedy, Drama, Ma...   \n",
       "14647  Action, Military, Mystery, Super Power, Drama,...   \n",
       "4953                                    Thriller, Sci-Fi   \n",
       "5660    Action, Adventure, Fantasy, Shounen, Super Power   \n",
       "8879   Action, Comedy, Historical, Parody, Samurai, S...   \n",
       "13720  Action, Drama, Fantasy, Military, Mystery, Sho...   \n",
       "5234   Action, Sci-Fi, Comedy, Historical, Parody, Sa...   \n",
       "723                       Military, Sci-Fi, Space, Drama   \n",
       "6377   Action, Comedy, Historical, Parody, Samurai, S...   \n",
       "8854                              Drama, School, Shounen   \n",
       "\n",
       "                                               sypnopsis  \n",
       "3446   \"In order for something to be obtained, someth...  \n",
       "14647  Gabi Braun and Falco Grice have been training ...  \n",
       "4953   The self-proclaimed mad scientist Rintarou Oka...  \n",
       "5660   Hunter x Hunter is set in a world where Hunter...  \n",
       "8879   Gintoki, Shinpachi, and Kagura return as the f...  \n",
       "13720  Seeking to restore humanity's diminishing hope...  \n",
       "5234   fter a one-year hiatus, Shinpachi Shimura retu...  \n",
       "723    The 150-year-long stalemate between the two in...  \n",
       "6377   hile Gintoki Sakata was away, the Yorozuya fou...  \n",
       "8854   s a wild youth, elementary school student Shou...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 Anime Based on Score\n",
    "df.sort_values(by='Score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "pHgkxbVVK6op"
   },
   "outputs": [],
   "source": [
    "#convert the Genres and sypnopsis which is a string to a list\n",
    "df['Genres'] = df['Genres'].apply(lambda x:x.split())\n",
    "df['sypnopsis'] = df['sypnopsis'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "S4fK_PqjLVIJ",
    "outputId": "a9c909ba-df02-4938-f1ec-c902a713e7f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>Genres</th>\n",
       "      <th>sypnopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>8.78</td>\n",
       "      <td>[Action,, Adventure,, Comedy,, Drama,, Sci-Fi,...</td>\n",
       "      <td>[In, the, year, 2071,, humanity, has, colonize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>8.39</td>\n",
       "      <td>[Action,, Drama,, Mystery,, Sci-Fi,, Space]</td>\n",
       "      <td>[other, day,, another, bounty—such, is, the, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>8.24</td>\n",
       "      <td>[Action,, Sci-Fi,, Adventure,, Comedy,, Drama,...</td>\n",
       "      <td>[Vash, the, Stampede, is, the, man, with, a, $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>7.27</td>\n",
       "      <td>[Action,, Mystery,, Police,, Supernatural,, Dr...</td>\n",
       "      <td>[ches, are, individuals, with, special, powers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>6.98</td>\n",
       "      <td>[Adventure,, Fantasy,, Shounen,, Supernatural]</td>\n",
       "      <td>[It, is, the, dark, century, and, the, people,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAL_ID                             Name  Score  \\\n",
       "0       1                     Cowboy Bebop   8.78   \n",
       "1       5  Cowboy Bebop: Tengoku no Tobira   8.39   \n",
       "2       6                           Trigun   8.24   \n",
       "3       7               Witch Hunter Robin   7.27   \n",
       "4       8                   Bouken Ou Beet   6.98   \n",
       "\n",
       "                                              Genres  \\\n",
       "0  [Action,, Adventure,, Comedy,, Drama,, Sci-Fi,...   \n",
       "1        [Action,, Drama,, Mystery,, Sci-Fi,, Space]   \n",
       "2  [Action,, Sci-Fi,, Adventure,, Comedy,, Drama,...   \n",
       "3  [Action,, Mystery,, Police,, Supernatural,, Dr...   \n",
       "4     [Adventure,, Fantasy,, Shounen,, Supernatural]   \n",
       "\n",
       "                                           sypnopsis  \n",
       "0  [In, the, year, 2071,, humanity, has, colonize...  \n",
       "1  [other, day,, another, bounty—such, is, the, l...  \n",
       "2  [Vash, the, Stampede, is, the, man, with, a, $...  \n",
       "3  [ches, are, individuals, with, special, powers...  \n",
       "4  [It, is, the, dark, century, and, the, people,...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "hPR07ZP2LXuh"
   },
   "outputs": [],
   "source": [
    "# remove space between two words\n",
    "df['Genres'] = df['Genres'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "df['sypnopsis'] = df['sypnopsis'].apply(lambda x:[i.replace(\" \",\"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "t0IMrkkRLq8o"
   },
   "outputs": [],
   "source": [
    "df['features'] = df['Genres'] + df['sypnopsis'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "P9h38FnqL98o"
   },
   "outputs": [],
   "source": [
    "new_df = df[['Name', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvHxVqs_Meg3",
    "outputId": "63fe2e5d-c493-4c32-cce8-24245d6bdba6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\AppData\\Local\\Temp\\ipykernel_4892\\1610446230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['features'] = new_df['features'].apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "# convert list to string\n",
    "new_df['features'] = new_df['features'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "oRfopwCWMTsq",
    "outputId": "263719f5-64f0-434c-a56c-3327102f7961"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>Action, Drama, Mystery, Sci-Fi, Space other da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trigun</td>\n",
       "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>Adventure, Fantasy, Shounen, Supernatural It i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16209</th>\n",
       "      <td>Daomu Biji Zhi Qinling Shen Shu</td>\n",
       "      <td>Adventure, Mystery, Supernatural No synopsis i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16210</th>\n",
       "      <td>Mieruko-chan</td>\n",
       "      <td>Comedy, Horror, Supernatural ko is a typical h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16211</th>\n",
       "      <td>Higurashi no Naku Koro ni Sotsu</td>\n",
       "      <td>Mystery, Dementia, Horror, Psychological, Supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16212</th>\n",
       "      <td>Yama no Susume: Next Summit</td>\n",
       "      <td>Adventure, Slice of Life, Comedy New Yama no S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>Scarlet Nexus</td>\n",
       "      <td>Action, Fantasy Solar calendar year 2020: grot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Name  \\\n",
       "0                         Cowboy Bebop   \n",
       "1      Cowboy Bebop: Tengoku no Tobira   \n",
       "2                               Trigun   \n",
       "3                   Witch Hunter Robin   \n",
       "4                       Bouken Ou Beet   \n",
       "...                                ...   \n",
       "16209  Daomu Biji Zhi Qinling Shen Shu   \n",
       "16210                     Mieruko-chan   \n",
       "16211  Higurashi no Naku Koro ni Sotsu   \n",
       "16212      Yama no Susume: Next Summit   \n",
       "16213                    Scarlet Nexus   \n",
       "\n",
       "                                                features  \n",
       "0      Action, Adventure, Comedy, Drama, Sci-Fi, Spac...  \n",
       "1      Action, Drama, Mystery, Sci-Fi, Space other da...  \n",
       "2      Action, Sci-Fi, Adventure, Comedy, Drama, Shou...  \n",
       "3      Action, Mystery, Police, Supernatural, Drama, ...  \n",
       "4      Adventure, Fantasy, Shounen, Supernatural It i...  \n",
       "...                                                  ...  \n",
       "16209  Adventure, Mystery, Supernatural No synopsis i...  \n",
       "16210  Comedy, Horror, Supernatural ko is a typical h...  \n",
       "16211  Mystery, Dementia, Horror, Psychological, Supe...  \n",
       "16212  Adventure, Slice of Life, Comedy New Yama no S...  \n",
       "16213  Action, Fantasy Solar calendar year 2020: grot...  \n",
       "\n",
       "[16206 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "6c5HJ2PdNDF5"
   },
   "outputs": [],
   "source": [
    "#Stemming is the process of producing morphological variants of a root/base word.\n",
    "\"\"\"\n",
    "root word \"like\" include:\n",
    "\n",
    "-> \"likes\"\n",
    "-> \"liked\"\n",
    "-> \"likely\"\n",
    "-> \"liking\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "XUDaOEt_bRS7"
   },
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    y = []\n",
    "    \n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "at3nyhwUNEyI",
    "outputId": "f41219e2-d9ba-4703-905a-f9ae76fc3781"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\AppData\\Local\\Temp\\ipykernel_4892\\3223666640.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['features'] = new_df['features'].apply(stem)\n"
     ]
    }
   ],
   "source": [
    "new_df['features'] = new_df['features'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVrrCBDLNE1A",
    "outputId": "0d85b2c0-b3d8-4f1c-b668-b6ba8dce57ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnab\\AppData\\Local\\Temp\\ipykernel_4892\\2700973631.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['features'] = new_df['features'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "new_df['features'] = new_df['features'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "my2nxB6cNE35",
    "outputId": "4854c2ae-e25a-4cc3-9e1f-460604d6eb26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>action, adventure, comedy, drama, sci-fi, spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>action, drama, mystery, sci-fi, space other da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trigun</td>\n",
       "      <td>action, sci-fi, adventure, comedy, drama, shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>action, mystery, police, supernatural, drama, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bouken Ou Beet</td>\n",
       "      <td>adventure, fantasy, shounen, supernatur it is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name  \\\n",
       "0                     Cowboy Bebop   \n",
       "1  Cowboy Bebop: Tengoku no Tobira   \n",
       "2                           Trigun   \n",
       "3               Witch Hunter Robin   \n",
       "4                   Bouken Ou Beet   \n",
       "\n",
       "                                            features  \n",
       "0  action, adventure, comedy, drama, sci-fi, spac...  \n",
       "1  action, drama, mystery, sci-fi, space other da...  \n",
       "2  action, sci-fi, adventure, comedy, drama, shou...  \n",
       "3  action, mystery, police, supernatural, drama, ...  \n",
       "4  adventure, fantasy, shounen, supernatur it is ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "XWks5a_BOnMl"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Countvectorizer is a method to convert text to numerical data\n",
    "\n",
    "The CountVectorizer will select the words/features/terms which occur the most frequently.\n",
    "It takes absolute values so if you set the ‘max_features = 3’, it will select the 3 most \n",
    "common words in the data.\n",
    "\n",
    "If ‘english’, a built-in stop word list for English is used. \n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "mpEydgS3OnPU"
   },
   "outputs": [],
   "source": [
    "vectors = cv.fit_transform(new_df['features']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bxvjcRnOnSQ",
    "outputId": "e2b258ee-dc20-4014-b224-08db8a897f80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "LvECY0A0NE6a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "zwMuO1s1NE8W"
   },
   "outputs": [],
   "source": [
    "#we use cosine similarity between these vectors to find their similarity.\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ek3tdRlxNE-9",
    "outputId": "ae03241b-1384-4c2f-fc12-7f5a87efc4fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16206, 16206)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5oJpuXQU7O-",
    "outputId": "faebcb8c-d6e8-426a-8889-4f2b27517458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3149, 0.34932619631159634),\n",
       " (5545, 0.33517751522573636),\n",
       " (1145, 0.31619510292053465),\n",
       " (5949, 0.2979355690895434),\n",
       " (15573, 0.2979355690895434),\n",
       " (365, 0.2931856917889426),\n",
       " (3669, 0.2922959000805237),\n",
       " (4028, 0.2878331051844618),\n",
       " (5000, 0.28444006199428723)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a tupple and stores every similarity index\n",
    "sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "tN7xSznnU7R7"
   },
   "outputs": [],
   "source": [
    "def recommend(anime):\n",
    "    movie_index = new_df[new_df['Name'] == anime].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:15]\n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLpHDa0DU7VO",
    "outputId": "fb7bb654-310c-407d-d4ef-6777d885773f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingeki no Kyojin Season 2\n",
      "Shingeki no Kyojin Season 3\n",
      "Mushrambo\n",
      "Shingeki no Kyojin Season 2 Movie: Kakusei no Houkou\n",
      "Shingeki! Kyojin Chuugakkou\n",
      "Noblesse: Pamyeol-ui Sijak\n",
      "Kekkai Sensen & Beyond\n",
      "Karas\n",
      "Shingeki no Kyotou\n",
      "Ajin\n",
      "Kamisama Kazoku\n",
      "Kuusou Kagaku Sekai Gulliver Boy\n",
      "Wo Jiao Bai Xiaofei\n",
      "Gyakkyou Burai Kaiji: Ultimate Survivor\n"
     ]
    }
   ],
   "source": [
    "recommend('Shingeki no Kyojin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yXA3-kz-D2uV",
    "outputId": "c2e4aa6c-53fa-477d-9eb1-c1a547b05403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boku no Hero Academia 4th Season\n",
      "Tiger & Bunny\n",
      "Ore wa Teppei\n",
      "Yume Senshi Wingman\n",
      "Boku no Hero Academia 2nd Season\n",
      "Samurai Flamenco\n",
      "Angel Densetsu\n",
      "Yuusha ni Narenakatta Ore wa Shibushibu Shuushoku wo Ketsui Shimashita. OVA\n",
      "Nisekoi\n",
      "Maoyuu Maou Yuusha\n",
      "One Punch Man 2nd Season\n",
      "Pandora Voxx Complete\n",
      "Double Decker! Doug & Kirill\n",
      "The Samurai\n"
     ]
    }
   ],
   "source": [
    "recommend('Boku no Hero Academia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFNfROgiU7YD",
    "outputId": "267682e9-4338-4797-f94f-0803fe1450fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Death Note: Rewrite\n",
      "Ghost Messenger\n",
      "Soul Eater\n",
      "Kite Liberator\n",
      "Shinigami no Ballad.\n",
      "Bleach: Memories in the Rain\n",
      "Yami no Shihosha Judge\n",
      "Isekai wa Smartphone to Tomo ni.\n",
      "Wan Jie Shen Zhu\n",
      "Platinum End\n",
      "Persona 3 the Movie 4: Winter of Rebirth\n",
      "Yume Senshi Wingman\n",
      "Da Yu Hai Tang (Movie)\n",
      "Koutetsujou no Kabaneri\n"
     ]
    }
   ],
   "source": [
    "recommend('Death Note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"similarities.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['similarities.joblib']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(similarity,filename,compress=(\"zlib\",9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3149, 0.34932619631159634),\n",
       " (5545, 0.33517751522573636),\n",
       " (1145, 0.31619510292053465),\n",
       " (5949, 0.2979355690895434),\n",
       " (15573, 0.2979355690895434),\n",
       " (365, 0.2931856917889426),\n",
       " (3669, 0.2922959000805237),\n",
       " (4028, 0.2878331051844618),\n",
       " (5000, 0.28444006199428723)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(enumerate(loaded_model[0])),reverse=True,key=lambda x:x[1])[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(anime):\n",
    "    movie_index = new_df[new_df['Name'] == anime].index[0]\n",
    "    distances = loaded_model[movie_index]\n",
    "    movies_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:15]\n",
    "    for i in movies_list:\n",
    "        print(new_df.iloc[i[0]].Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingeki no Kyojin Season 2\n",
      "Shingeki no Kyojin Season 3\n",
      "Mushrambo\n",
      "Shingeki no Kyojin Season 2 Movie: Kakusei no Houkou\n",
      "Shingeki! Kyojin Chuugakkou\n",
      "Noblesse: Pamyeol-ui Sijak\n",
      "Kekkai Sensen & Beyond\n",
      "Karas\n",
      "Shingeki no Kyotou\n",
      "Ajin\n",
      "Kamisama Kazoku\n",
      "Kuusou Kagaku Sekai Gulliver Boy\n",
      "Wo Jiao Bai Xiaofei\n",
      "Gyakkyou Burai Kaiji: Ultimate Survivor\n"
     ]
    }
   ],
   "source": [
    "recommend(\"Shingeki no Kyojin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import time\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with open(filename, 'wb') as f:\n",
    "    dump(data, f)\n",
    "raw_dump_duration = time.time() - start\n",
    "print(\"Raw dump duration: %0.3fs\" % raw_dump_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title('Anime Recommendation App')\n",
    "st.write('Based on your favs we will give you another 20 anime to binge watch')\n",
    "image = Image.open('TitleImage.png')\n",
    "st.image(image, use_column_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache(allow_output_mutation=True)\n",
    "def load(model_path):\n",
    "    df = pd.read_pickle(model_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load at 0x000001A02F66CAF0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/df/df\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:715\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message):\n\u001b[1;32m--> 715\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:637\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_optional_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:767\u001b[0m, in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    756\u001b[0m update_hash(\n\u001b[0;32m    757\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[0;32m    758\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    761\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    762\u001b[0m )\n\u001b[0;32m    764\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m \u001b[43mupdate_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_hasher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHashReason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCACHING_FUNC_BODY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[0;32m    775\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[0;32m    777\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:108\u001b[0m, in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    105\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[0;32m    107\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[1;32m--> 108\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:385\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:374\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    356\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    624\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[0;32m    628\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `load()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function load at 0x000001A02F66CAF0>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "dataframe = load('models/df/df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m option \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mselectbox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease select your favorite anime\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[43mdataframe\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "option = st.selectbox('Please select your favorite anime', (dataframe.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'option' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m st\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou selected:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43moption\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'option' is not defined"
     ]
    }
   ],
   "source": [
    "st.write('You selected:', option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (st.button('Get Recommendation')):\n",
    "    # dataframe = load('../models/df.pkl')\n",
    "    result = recommend(option)\n",
    "    st.write(result)\n",
    "    st.balloons()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNMF6PYUDOuJRP0Mi9l0in1",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
